{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/Kulbear/deep-learning-coursera/blob/master/Convolutional%20Neural%20Networks/Keras%20-%20Tutorial%20-%20Happy%20House%20v1.ipynb\n",
    "# Data Augmentation Keras ImageDataGenerator https://keras.io/preprocessing/image/\n",
    "# Regularisation: Dropout, L2\n",
    "# Optmisation: Batch normalisation, optmiser choice\n",
    "# Parameter tuning: Architecture\n",
    "#https://helpx.adobe.com/hk_en/photoshop/using/image-size-resolution.html#resampling\n",
    "#Each pixel in image is 1 byte (8 bit) sized in each colour channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input,Dense,Activation,ZeroPadding2D, BatchNormalization,Flatten,Conv2D\n",
    "from keras.layers import AveragePooling2D,MaxPooling2D,Dropout,GlobalMaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils, np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "#from kt_utils import * \n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    train=pd.read_csv(path+'/train.csv')\n",
    "    test=pd.read_csv(path+'/test.csv')\n",
    "    return train,test\n",
    "\n",
    "train,test=read_data('./Datasets')\n",
    "\n",
    "def generate_input(path,image_ids):\n",
    "    for id in image_ids:\n",
    "        img=image.load_img(path+id,target_size=(64,64))\n",
    "        x=image.img_to_array(img)\n",
    "        x=np.expand_dims(x,axis=0)\n",
    "        x=preprocess_input(x)\n",
    "        yield x\n",
    "    \n",
    "X_train=np.concatenate([feat for feat in generate_input('./Datasets/Train/',train['ID'])])\n",
    "X_test=np.concatenate([feat for feat in generate_input('./Datasets/Test/',test['ID'])])\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "Y_train=lb.fit_transform(train['Class'])\n",
    "#np_utils.to_categorical(train['Class'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_detector(input_shape):\n",
    "    X_input=Input(input_shape)\n",
    "    X=ZeroPadding2D((3,3))(X_input)\n",
    "    #CONV-->BN-->RELU block on input\n",
    "    X=Conv2D(32, (7,7),strides=(1,1),name='conv0')(X)\n",
    "    X=BatchNormalization(axis=3,name='bn0')(X)\n",
    "    X=Activation('relu')(X)\n",
    "    #Maxpool\n",
    "    X=MaxPooling2D((2,2),name='max_pool')(X)\n",
    "    #Flatten\n",
    "    X=Flatten()(X)\n",
    "    X=Dense(3,activation='softmax',name='fc')(X)\n",
    "    model=Model(inputs=X_input,outputs=X,name='age_detector')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "19906/19906 [==============================] - 315s 16ms/step - loss: 4.0394 - acc: 0.5612\n",
      "Epoch 2/40\n",
      "19906/19906 [==============================] - 238s 12ms/step - loss: 1.4404 - acc: 0.6027\n",
      "Epoch 3/40\n",
      "19906/19906 [==============================] - 241s 12ms/step - loss: 1.2253 - acc: 0.6288\n",
      "Epoch 4/40\n",
      "19906/19906 [==============================] - 241s 12ms/step - loss: 0.8969 - acc: 0.6616\n",
      "Epoch 5/40\n",
      "19906/19906 [==============================] - 242s 12ms/step - loss: 0.8946 - acc: 0.6779\n",
      "Epoch 6/40\n",
      "19906/19906 [==============================] - 243s 12ms/step - loss: 0.7309 - acc: 0.7000\n",
      "Epoch 7/40\n",
      "19906/19906 [==============================] - 238s 12ms/step - loss: 0.6799 - acc: 0.7190\n",
      "Epoch 8/40\n",
      "19906/19906 [==============================] - 237s 12ms/step - loss: 0.6678 - acc: 0.7251\n",
      "Epoch 9/40\n",
      "19906/19906 [==============================] - 235s 12ms/step - loss: 0.6362 - acc: 0.7389\n",
      "Epoch 10/40\n",
      "19906/19906 [==============================] - 234s 12ms/step - loss: 0.6141 - acc: 0.7435\n",
      "Epoch 11/40\n",
      "19906/19906 [==============================] - 233s 12ms/step - loss: 0.5986 - acc: 0.7565\n",
      "Epoch 12/40\n",
      "19906/19906 [==============================] - 234s 12ms/step - loss: 0.5941 - acc: 0.7573\n",
      "Epoch 13/40\n",
      "19906/19906 [==============================] - 235s 12ms/step - loss: 0.5693 - acc: 0.7655\n",
      "Epoch 14/40\n",
      "19906/19906 [==============================] - 235s 12ms/step - loss: 0.5509 - acc: 0.7735\n",
      "Epoch 15/40\n",
      "19906/19906 [==============================] - 235s 12ms/step - loss: 0.5535 - acc: 0.7765\n",
      "Epoch 16/40\n",
      "19906/19906 [==============================] - 235s 12ms/step - loss: 0.5276 - acc: 0.7844\n",
      "Epoch 17/40\n",
      "19906/19906 [==============================] - 235s 12ms/step - loss: 0.5151 - acc: 0.7871\n",
      "Epoch 18/40\n",
      "19906/19906 [==============================] - 235s 12ms/step - loss: 0.4938 - acc: 0.8016\n",
      "Epoch 19/40\n",
      "19906/19906 [==============================] - 236s 12ms/step - loss: 0.4985 - acc: 0.7951\n",
      "Epoch 20/40\n",
      "19906/19906 [==============================] - 236s 12ms/step - loss: 0.4839 - acc: 0.8047\n",
      "Epoch 21/40\n",
      "19906/19906 [==============================] - 236s 12ms/step - loss: 0.4776 - acc: 0.8077\n",
      "Epoch 22/40\n",
      "19906/19906 [==============================] - 236s 12ms/step - loss: 0.4506 - acc: 0.8149\n",
      "Epoch 23/40\n",
      "19906/19906 [==============================] - 236s 12ms/step - loss: 0.4445 - acc: 0.8198\n",
      "Epoch 24/40\n",
      "19906/19906 [==============================] - 236s 12ms/step - loss: 0.4235 - acc: 0.8273\n",
      "Epoch 25/40\n",
      "19906/19906 [==============================] - 236s 12ms/step - loss: 0.4122 - acc: 0.8323\n",
      "Epoch 26/40\n",
      "19906/19906 [==============================] - 362s 18ms/step - loss: 0.3981 - acc: 0.8391\n",
      "Epoch 27/40\n",
      "19906/19906 [==============================] - 458s 23ms/step - loss: 0.4013 - acc: 0.8364\n",
      "Epoch 28/40\n",
      "19906/19906 [==============================] - 484s 24ms/step - loss: 0.3741 - acc: 0.8524\n",
      "Epoch 29/40\n",
      "19906/19906 [==============================] - 517s 26ms/step - loss: 0.3669 - acc: 0.8520\n",
      "Epoch 30/40\n",
      "19906/19906 [==============================] - 493s 25ms/step - loss: 0.3664 - acc: 0.8562\n",
      "Epoch 31/40\n",
      "19906/19906 [==============================] - 433s 22ms/step - loss: 0.3370 - acc: 0.8644\n",
      "Epoch 32/40\n",
      "19906/19906 [==============================] - 494s 25ms/step - loss: 0.3291 - acc: 0.8698\n",
      "Epoch 33/40\n",
      "19906/19906 [==============================] - 525s 26ms/step - loss: 0.3342 - acc: 0.8667\n",
      "Epoch 34/40\n",
      "19906/19906 [==============================] - 523s 26ms/step - loss: 0.3202 - acc: 0.8731\n",
      "Epoch 35/40\n",
      "19906/19906 [==============================] - 521s 26ms/step - loss: 0.3585 - acc: 0.8575\n",
      "Epoch 36/40\n",
      "19906/19906 [==============================] - 526s 26ms/step - loss: 0.2869 - acc: 0.8895\n",
      "Epoch 37/40\n",
      "19906/19906 [==============================] - 534s 27ms/step - loss: 0.2749 - acc: 0.8935\n",
      "Epoch 38/40\n",
      "19906/19906 [==============================] - 534s 27ms/step - loss: 0.2740 - acc: 0.8945\n",
      "Epoch 39/40\n",
      "19906/19906 [==============================] - 532s 27ms/step - loss: 0.2610 - acc: 0.8999\n",
      "Epoch 40/40\n",
      "19906/19906 [==============================] - 525s 26ms/step - loss: 0.2799 - acc: 0.8943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2139d30c4a8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_detector=age_detector(X_train.shape[1:])\n",
    "age_detector.compile('adam','categorical_crossentropy',metrics=['accuracy'])\n",
    "age_detector.fit(X_train,Y_train,epochs=40,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
